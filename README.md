# Live2Dアニメキャラクター×AIチャット アプリ

このプロジェクトは、Live2DアニメキャラクターとOpenAI(ChatGPT)APIを組み合わせたインタラクティブなWebアプリケーションです。ユーザーがテキストを入力すると、キャラクターが表情豊かに反応し、AIの返答を音声で読み上げます。

## 目次
- [特徴](#特徴)
- [技術スタック](#技術スタック)
- [セットアップ方法](#セットアップ方法)
- [開発環境の起動](#開発環境の起動)
- [Live2Dモデルの設定](#live2dモデルの設定)
- [リップシンク機能](#リップシンク機能)
- [変更履歴](#変更履歴)
- [ライセンス](#ライセンス)

## 特徴

- Live2Dキャラクターの表示とアニメーション
- ChatGPT APIを使用したインテリジェントな会話
- テキスト読み上げによる音声応答
- リップシンク（音声に合わせた口の動き）機能
- 感情分析に基づくキャラクターの表情変化

## 技術スタック

### フロントエンド
- HTML5/CSS3/JavaScript
- [Live2D Cubism SDK for Web](https://www.live2d.com/en/download/cubism-sdk/download-web/)
- [pixi-live2d-display](https://github.com/guansss/pixi-live2d-display)（Pixi.js上でのLive2D表示用）
- Web Audio API（音声再生・リップシンク用）

### バックエンド
- Node.js + Express（サーバーサイド処理）
- OpenAI API（ChatGPT 3.5/4）
- 音声合成サービス
  - [VOICEVOX](https://voicevox.hiroshiba.jp/)（無料の音声合成エンジン）
  - Azure Cognitive Services（オプション）

## セットアップ方法

### 前提条件
- Node.js (バージョン14以上)
- npm または yarn
- OpenAI APIキー
- VOICEVOX（無料の音声合成エンジン）をローカルで起動するか、Azure Cognitive Servicesのキー

### インストール手順
1. リポジトリをクローン:
```
git clone https://github.com/mamama6147/live2d-ai-chat.git
cd live2d-ai-chat
```

2. 依存関係のインストール:
```
# クライアント側
cd client
npm install

# サーバー側
cd ../server
npm install
```

3. 環境変数の設定:
サーバーディレクトリに `.env.template` ファイルが用意されています。これをコピーして `.env` ファイルを作成し、必要な情報を設定してください。

**注意**: `.env` ファイルには機密情報が含まれるため、Gitリポジトリにコミットしないでください。

```
# 基本設定の例
OPENAI_API_KEY=your_openai_api_key
TTS_SERVICE=voicevox
VOICEVOX_ENDPOINT=http://localhost:50021
VOICEVOX_SPEAKER_ID=3  # ずんだもん（ノーマル）
```

4. Live2Dモデルの配置:
公式サンプルまたは自作モデルを `client/public/models` ディレクトリに配置します。

### VOICEVOXの設定

このプロジェクトはデフォルトでVOICEVOXを使用します。VOICEVOXは無料の日本語音声合成エンジンで、様々なキャラクターボイスが利用可能です。

1. [VOICEVOX公式サイト](https://voicevox.hiroshiba.jp/)からソフトウェアをダウンロード・インストール
2. VOICEVOXを起動し、バックグラウンドで実行したままにする
3. デフォルトでは `http://localhost:50021` でサービスが提供されます

#### サポートされているVOICEVOX話者

以下のIDで多数の話者とスタイルをサポートしています：
- 四国めたん: 2（ノーマル）、0（あまあま）、6（ツンツン）など
- ずんだもん: 3（ノーマル）、1（あまあま）、7（ツンツン）など
- その他多数の話者

詳細はクライアント設定UIから選択するか、VOICEVOXのソフトウェアで確認できます。

## 開発環境の起動

```
# サーバー起動 (server ディレクトリ内で)
npm run dev

# クライアント開発サーバー起動 (client ディレクトリ内で)
npm run dev
```

## Live2Dモデルの設定

### モデルのリップシンクパラメータ

Live2Dモデルのリップシンク（口パク）機能を使用するには、モデルが適切なパラメータを持っている必要があります。このプロジェクトでは、以下のようなパラメータ名を自動的に検出して口の動きに使用します：

- 一般的なLive2Dパラメータ
  - `ParamMouthOpenY`
  - `PARAM_MOUTH_OPEN_Y`
  - `ParamMouthOpen`
  - `PARAM_MOUTH_OPEN`

- 虹色まおモデル用パラメータ
  - `ParamA` (虹色まおのmodel3.jsonでLipSyncグループに指定されているパラメータ)

モデルによって使用されるパラメータが異なる場合は、`client/main.js`の以下の部分を修正してください：

```javascript
// 口の開閉値を複数のパラメータに適用する関数
function applyMouthOpenValue(value) {
  // ...
  const mouthParams = [
    'ParamA',             // 虹色まおの口パクパラメータ
    'ParamMouthOpenY',
    'PARAM_MOUTH_OPEN_Y',
    // 必要に応じて他のパラメータを追加
  ];
  // ...
}
```

### 口の開き具合の設定

キャラクターの口の開き具合は、`client/main.js`の`applyMouthOpenValue`関数内で調整できます。最新バージョンでは3.8倍に増幅されています。

```javascript
// 口の開きを大きくするために値を増幅（3.8倍に増幅）
const amplifiedValue = Math.min(value * 3.8, 1);
```

この値を変更することで、口の開き具合を調整できます。ただし、最大値は1.0なので、どんなに大きく設定しても`Math.min`関数により1.0を超えることはありません。

## リップシンク機能

リップシンク機能はWeb Audio APIを利用して音声の音量を分析し、それに応じてキャラクターの口の動きをリアルタイムで制御します。この機能には以下のモードがあります：

- **自動**: 音声ファイルが正常に再生された場合は音声解析ベースのリップシンク、失敗した場合はダミーリップシンクにフォールバック
- **音声解析**: 音声のフーリエ変換を使用してリアルタイムに口の開閉を制御
- **単純**: 単純なパターンで口をパクパク動かす（開く0.2秒、閉じる0.2秒、待機0.2秒の繰り返し）
- **ダミー**: ランダムノイズを用いた簡易的な口パク動作（音声ファイルが無い場合やデバッグ用）
- **オフ**: リップシンク機能を無効化

この機能はクライアント側の設定UIから切り替えることができます。

### 主な機能と改善点

最新バージョンでは以下の機能が実装されています：

1. **音声の事前解析モード**: 音声再生前に音声データを事前解析して詳細な口の動きデータを生成し、自然な口の動きを実現
2. **タイミング同期**: 音声再生位置と口の動きのタイミングを正確に同期
3. **ピーク検出と強調**: 音声の強い部分（子音や音節の始まり）をより明確に表現
4. **人間の声に特化した分析**: 母音の周波数帯域（特に500Hz～2000Hz）により重点を置いた解析
5. **複雑なリズムパターン**: 複数の周波数パターンを組み合わせた自然な口の動き
6. **音量変化率による動的調整**: 音量の変化率を考慮して口の動きに反映
7. **エラーハンドリングと復旧処理**: 音声ファイル再生エラーが発生した場合の復旧処理
8. **単純口パクアニメーション**: 音声分析を行わず、単純なパターンで口をパクパク動かすモード

## 変更履歴

### 最新バージョン (v1.7.0)
- 単純口パクアニメーションモードを追加（開く0.2秒、閉じる0.2秒、閉じたまま0.2秒待機を繰り返す）
- リップシンクモードの選択肢に「単純」オプションを追加

### 過去のバージョン
- v1.6.0: `OfflineAudioContext` を完全に排除し、Chrome 124以降での例外を防止
- v1.5.3: 音声事前解析中のOfflineAudioContextのタイミングエラーを修正
- v1.5.2: 音声再生の問題を修正し、安定性を向上
- v1.5.1: 音声事前解析中のレンダリング処理を修正し、安定性を向上
- v1.5: 音声の事前解析モードを導入し、より自然で多様な口の動きを実現
- v1.4: リップシンク機能の大幅改善（FFTサイズ増加、人間の声に特化した解析）
- v1.3: 複数回の口の動きパターンと動的調整を実装
- v1.2: 音量に応じた動的な口の開閉と自然な口の動きを実現
- v1.1: リップシンク機能の改善（反応速度・精度・表現力の向上）
- v1.0: 初期リリース

## ライセンス

このプロジェクトは開発中です。Live2Dモデルを含む各コンポーネントのライセンスに従ってください。