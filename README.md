# Live2Dアニメキャラクター×AIチャット アプリ

このプロジェクトは、Live2DアニメキャラクターとOpenAI(ChatGPT)APIを組み合わせたインタラクティブなWebアプリケーションです。ユーザーがテキストを入力すると、キャラクターが表情豊かに反応し、AIの返答を音声で読み上げます。

## 特徴

- Live2Dキャラクターの表示とアニメーション
- ChatGPT APIを使用したインテリジェントな会話
- テキスト読み上げによる音声応答
- リップシンク（音声に合わせた口の動き）機能
- 感情分析に基づくキャラクターの表情変化

## 技術スタック

### フロントエンド
- HTML5/CSS3/JavaScript
- [Live2D Cubism SDK for Web](https://www.live2d.com/en/download/cubism-sdk/download-web/)
- [pixi-live2d-display](https://github.com/guansss/pixi-live2d-display)（Pixi.js上でのLive2D表示用）
- Web Audio API（音声再生・リップシンク用）

### バックエンド
- Node.js + Express（サーバーサイド処理）
- OpenAI API（ChatGPT 3.5/4）
- 音声合成サービス
  - [VOICEVOX](https://voicevox.hiroshiba.jp/)（無料の音声合成エンジン）
  - Azure Cognitive Services（オプション）

## セットアップ

### 前提条件
- Node.js (バージョン14以上)
- npm または yarn
- OpenAI APIキー
- VOICEVOX（無料の音声合成エンジン）をローカルで起動するか、Azure Cognitive Servicesのキー

### インストール手順
1. リポジトリをクローン:
```
git clone https://github.com/mamama6147/live2d-ai-chat.git
cd live2d-ai-chat
```

2. 依存関係のインストール:
```
# クライアント側
cd client
npm install

# サーバー側
cd ../server
npm install
```

3. 環境変数の設定:
サーバーディレクトリに `.env` ファイルを作成し、以下のように設定:
```
OPENAI_API_KEY=your_openai_api_key
TTS_SERVICE=voicevox
VOICEVOX_ENDPOINT=http://localhost:50021
VOICEVOX_SPEAKER_ID=3  # ずんだもん（ノーマル）
```

4. Live2Dモデルの配置:
公式サンプルまたは自作モデルを `client/public/models` ディレクトリに配置します。

### VOICEVOXの設定

このプロジェクトはデフォルトでVOICEVOXを使用します。VOICEVOXは無料の日本語音声合成エンジンで、様々なキャラクターボイスが利用可能です。

1. [VOICEVOX公式サイト](https://voicevox.hiroshiba.jp/)からソフトウェアをダウンロード・インストール
2. VOICEVOXを起動し、バックグラウンドで実行したままにする
3. デフォルトでは `http://localhost:50021` でサービスが提供されます

#### サポートされているVOICEVOX話者

以下のIDで多数の話者とスタイルをサポートしています：
- 四国めたん: 2（ノーマル）、0（あまあま）、6（ツンツン）など
- ずんだもん: 3（ノーマル）、1（あまあま）、7（ツンツン）など
- その他多数の話者

詳細はクライアント設定UIから選択するか、VOICEVOXのソフトウェアで確認できます。

## 開発環境の起動

```
# サーバー起動 (server ディレクトリ内で)
npm run dev

# クライアント開発サーバー起動 (client ディレクトリ内で)
npm run dev
```

## Live2Dモデルについて

### モデルのリップシンクパラメータ

Live2Dモデルのリップシンク（口パク）機能を使用するには、モデルが適切なパラメータを持っている必要があります。このプロジェクトでは、以下のようなパラメータ名を自動的に検出して口の動きに使用します：

- 一般的なLive2Dパラメータ
  - `ParamMouthOpenY`
  - `PARAM_MOUTH_OPEN_Y`
  - `ParamMouthOpen`
  - `PARAM_MOUTH_OPEN`

- 虹色まおモデル用パラメータ
  - `ParamA` (虹色まおのmodel3.jsonでLipSyncグループに指定されているパラメータ)

モデルによって使用されるパラメータが異なる場合は、`client/main.js`の以下の部分を修正してください：

```javascript
// 口の開閉値を複数のパラメータに適用する関数
function applyMouthOpenValue(value) {
  // ...
  const mouthParams = [
    'ParamA',             // 虹色まおの口パクパラメータ
    'ParamMouthOpenY',
    'PARAM_MOUTH_OPEN_Y',
    // 必要に応じて他のパラメータを追加
  ];
  // ...
}
```

### 口の開き具合の設定

キャラクターの口の開き具合は、`client/main.js`の`applyMouthOpenValue`関数内で調整できます。v1.5では3.8倍に増幅されています。

```javascript
// 口の開きを大きくするために値を増幅（3.8倍に増幅）
const amplifiedValue = Math.min(value * 3.8, 1);
```

この値を変更することで、口の開き具合を調整できます。ただし、最大値は1.0なので、どんなに大きく設定しても`Math.min`関数により1.0を超えることはありません。

## リップシンク機能について

リップシンク機能はWeb Audio APIを利用して音声の音量を分析し、それに応じてキャラクターの口の動きをリアルタイムで制御します。この機能には3つのモードがあります：

- **自動**: 音声ファイルが正常に再生された場合は音声解析ベースのリップシンク、失敗した場合はダミーリップシンクにフォールバック
- **音声解析**: 音声のフーリエ変換を使用してリアルタイムに口の開閉を制御
- **ダミー**: ランダムノイズを用いた簡易的な口パク動作（音声ファイルが無い場合やデバッグ用）
- **オフ**: リップシンク機能を無効化

この機能はクライアント側の設定UIから切り替えることができます。

### リップシンク機能の改善点（v1.5）

最新のアップデート（v1.5）では、リップシンク機能に重大な改善を加えました：

1. **音声の事前解析モードの導入**: 音声再生前に音声データを事前解析して詳細な口の動きデータを生成し、1つの音声で複数回の自然な口の動きを実現
2. **タイミング同期の強化**: 音声再生位置と口の動きのタイミングを正確に同期させる機能を実装
3. **ピーク検出と強調**: 音声の強い部分（子音や音節の始まり）をより明確に表現し、はっきりとした発音を視覚的に表現
4. **オフラインオーディオコンテキスト**: 高速な事前解析のために`OfflineAudioContext`を導入
5. **スムージング処理の最適化**: 口の動きがぎこちなくならないよう、適切なスムージングを適用
6. **音節パターンの再現**: 自然な会話の音節パターンを再現するアルゴリズムを実装
7. **人間の音声に特化した解析**: 母音の周波数帯域（特に500Hz～2000Hz）により重点を置いた解析を強化

これらの改善により、キャラクターの口の動きがより自然で多様になり、実際の人間の発話パターンに近い動きが実現されました。

### リップシンク機能の改善点（v1.4）

v1.4では、リップシンク機能に以下の改善を加えました：

1. **より高精度な音声解析**: FFTサイズを2048に拡大し、より正確な周波数分析を実現
2. **人間の声に特化した周波数解析**: 母音が集中する500Hz〜2000Hz帯域に重点を置いた重み付け解析を導入
3. **反応速度の大幅な向上**: スムージング係数を0.9に高め、音声の変化にほぼリアルタイムで反応
4. **複雑なリズムパターンの導入**: 複数の周波数パターンを組み合わせた自然な口の動きを実現
5. **音声の急激な変化への対応強化**: 子音などの急な音量変化にも追従する機能を追加
6. **増幅率の最適化**: 口の開き具合の増幅率を3.5に調整し、より明確な口の動きを表現
7. **更新頻度の向上**: ダミーリップシンクの更新間隔を15msに短縮（約66.7FPS）で、より滑らかな動きを実現

### リップシンク機能の改善点（v1.3）

v1.3では、リップシンク機能に以下の改善を加えました：

1. **一度の音声での複数回の口の動きを実現**: 1回の音声で口が複数回パクパク動くようになり、より自然な動きを実現
2. **より反応性の高い口の動き**: スムージング係数を0.8に向上させ、音声の変化にさらに早く反応するよう改善
3. **周期的な変調の追加**: 音声に周期的な変調を加えることで、音声中でも口が常に自然に動くように改善
4. **音量変化率による動的調整**: 音量の変化率を考慮して口の動きに反映し、より自然な会話表現を実現
5. **ダミーリップシンクの改善**: 複雑なパターンの組み合わせで、よりリアルなダミーリップシンクを実現
6. **口の開閉の強調**: 増幅率を3.0に引き上げ、キャラクターの口の動きをより強調
7. **更新頻度の向上**: 20msごとの更新（約50FPS）により、より滑らかな口の動きを実現

### リップシンク機能の改善点（v1.2）

v1.2では、リップシンク機能に以下の改善を加えました：

1. **音量に応じた動的な口の開閉**: 音声の音量が小さくなると口を閉じ、大きくなると口を開くようになりました
2. **音量しきい値の導入**: 一定の音量以下では口を完全に閉じるようになり、より自然な口の動きを実現
3. **反応速度の向上**: スムージング係数を0.6に増加させ、より素早く音声の変化に追従
4. **口の開閉の強調**: 音量に応じた口の開き具合を最大2.5倍に増幅し、より明確な口の動きを表現
5. **解析精度の向上**: FFTサイズを1024に増加させ、より詳細な音声解析を実現
6. **フレームレートの向上**: ダミーリップシンクの更新間隔を25msに短縮し、より滑らかな動きを実現

### リップシンク機能の改善点（v1.1）

v1.1では、リップシンク機能に以下の改善を加えました：

1. **反応速度の向上**: スムージング係数を0.3から0.5に増加させ、口の動きが音声により速く追従するようにしました
2. **解析精度の向上**: FFTサイズを256から512に増加させ、音声解析の精度を向上させました
3. **口の開閉度の強調**: 口の開き具合を1.5倍から2.0倍に増幅し、よりはっきりと口の動きが見えるようにしました
4. **フレームレートの向上**: ダミーリップシンクのアップデート間隔を50msから33msに短縮し、より滑らかな動きを実現しました
5. **人間の声に合わせた分析**: 音声解析時に人間の声の周波数帯（約80Hz～3000Hz）に重点を置くように調整しました

## 機能実装ステータス

- [x] プロジェクト構造のセットアップ
- [x] Live2Dモデル表示
- [x] ChatGPT API連携
- [x] 音声合成機能（VOICEVOX/Azure）
- [x] リップシンク実装
- [x] 表情変化の実装
- [x] チャットUI

## 変更履歴

### v1.5
- 音声の事前解析モードを導入し、より自然で多様な口の動きを実現
- 音声再生位置と口の動きの正確な同期を実装
- 子音や音節の始まりをより強調する機能を追加
- オフラインオーディオコンテキストによる高速かつ詳細な音声解析を実現
- 口の動きのスムージングと自然な音節パターンの再現を強化
- 増幅率を3.8倍に調整して、より視認性の高い口の動きを実現

### v1.4
- リップシンク機能のさらなる改善（より自然ではきはきとした口の動き）
- 音声分析アルゴリズムの精度向上（FFTサイズ2048に拡大）
- 人間の声の周波数帯域に特化した重み付け解析を導入
- 複雑なリズムパターンによる自然な口の動きの実現
- ダミーリップシンクの更新頻度向上（約66.7FPS）

### v1.3
- リップシンク機能の大幅改善（1回の音声で複数回口がパクパク動くように）
- 口の動きをより反応的かつ自然に改善
- 音量変化率を用いた動的な口の動き調整を実装
- 周期的な変調を加えることでより自然な口の動きを実現
- ダミーリップシンク機能の向上
- 更新頻度の向上（約50FPS）による滑らかな動き

### v1.2
- リップシンク機能の大幅改善（音量に応じた動的な口の開閉）
- 音量しきい値の導入による自然な口の動き
- 音声解析アルゴリズムの精度向上
- 口の動きの増幅率と反応速度の調整

### v1.1
- リップシンク機能の改善（反応速度・精度・表現力の向上）
- 音声解析アルゴリズムの調整
- 口の動きの増幅率を増加

### v1.0
- 初期リリース

## ライセンス

このプロジェクトは開発中です。Live2Dモデルを含む各コンポーネントのライセンスに従ってください。